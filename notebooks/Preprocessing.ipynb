{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:50:19.100163Z",
     "iopub.status.busy": "2025-04-12T18:50:19.099866Z",
     "iopub.status.idle": "2025-04-12T18:50:25.682575Z",
     "shell.execute_reply": "2025-04-12T18:50:25.681742Z",
     "shell.execute_reply.started": "2025-04-12T18:50:19.100136Z"
    },
    "id": "qKjU5TZZQv2B",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T18:50:25.685014Z",
     "iopub.status.busy": "2025-04-12T18:50:25.684685Z",
     "iopub.status.idle": "2025-04-12T18:50:26.140192Z",
     "shell.execute_reply": "2025-04-12T18:50:26.139482Z",
     "shell.execute_reply.started": "2025-04-12T18:50:25.684995Z"
    },
    "id": "d_roGy03RVk_",
    "outputId": "584d5904-2d9c-4055-82bd-f3b7989d3745",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Punkt tokenizer, which is used for tokenizing\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Download stopwords dataset\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:50:26.141254Z",
     "iopub.status.busy": "2025-04-12T18:50:26.140962Z",
     "iopub.status.idle": "2025-04-12T18:50:26.146279Z",
     "shell.execute_reply": "2025-04-12T18:50:26.145501Z",
     "shell.execute_reply.started": "2025-04-12T18:50:26.141229Z"
    },
    "id": "AUyBCtv6RcfE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_train_val(input_csv_path, val_size, random_state=42):\n",
    "\n",
    "    data = pd.read_csv(input_csv_path)\n",
    "\n",
    "    #length of data\n",
    "    total_data_len = len(data)\n",
    "\n",
    "    print(f\"Total length before splitting : {total_data_len}\")\n",
    "\n",
    "    if total_data_len <= val_size:\n",
    "        raise ValueError(f\"Dataset has less samples than {val_size}. Can't proceed further \\n Total Training set length = {total_data_len}\")\n",
    "\n",
    "    # Create random indices for validation set\n",
    "    np.random.seed(random_state)\n",
    "    val_index = np.random.choice(total_data_len, val_size, replace=False)\n",
    "\n",
    "    # Split the dataset\n",
    "    validation_data = data.iloc[val_index]\n",
    "    training_data = data.drop(val_index)\n",
    "\n",
    "    return training_data, validation_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T18:50:26.147347Z",
     "iopub.status.busy": "2025-04-12T18:50:26.147174Z",
     "iopub.status.idle": "2025-04-12T18:50:31.791200Z",
     "shell.execute_reply": "2025-04-12T18:50:31.790521Z",
     "shell.execute_reply.started": "2025-04-12T18:50:26.147333Z"
    },
    "id": "mjgkankjSKFg",
    "outputId": "6d77ae27-836c-47da-8c0a-37eab53eb992",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length before splitting : 13879\n",
      "Training set size: 13379\n",
      "Validation set size: 500\n"
     ]
    }
   ],
   "source": [
    "training_data, validation_data = split_train_val('/kaggle/input/original-dataset/train.csv',500)\n",
    "print(f\"Training set size: {len(training_data)}\")\n",
    "print(f\"Validation set size: {len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-12T18:50:31.792324Z",
     "iopub.status.busy": "2025-04-12T18:50:31.792063Z",
     "iopub.status.idle": "2025-04-12T18:50:31.843875Z",
     "shell.execute_reply": "2025-04-12T18:50:31.843284Z",
     "shell.execute_reply.started": "2025-04-12T18:50:31.792305Z"
    },
    "id": "x5xy0DONSdE3",
    "outputId": "88adf3d8-cfaf-4329-eec5-401775610a1c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 100\n"
     ]
    }
   ],
   "source": [
    "#loading test data\n",
    "input_test_data='/kaggle/input/original-dataset/test.csv'\n",
    "test_data = pd.read_csv(input_test_data)\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:59:23.299455Z",
     "iopub.status.busy": "2025-04-12T18:59:23.298904Z",
     "iopub.status.idle": "2025-04-12T18:59:23.304123Z",
     "shell.execute_reply": "2025-04-12T18:59:23.303480Z",
     "shell.execute_reply.started": "2025-04-12T18:59:23.299435Z"
    },
    "id": "ZbbJe4_5Tg-n",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuation(text):\n",
    "    if not isinstance(text, str):\n",
    "        return str(text)\n",
    "\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "    # Sentence segmentation (keeps boundaries)\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    processed_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Remove punctuation (except needed for sentence boundaries)\n",
    "        sentence = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", sentence)\n",
    "\n",
    "        # Tokenize words\n",
    "        words = word_tokenize(sentence)\n",
    "        \n",
    "    # Join sentences back into a single string\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:59:24.638225Z",
     "iopub.status.busy": "2025-04-12T18:59:24.637498Z",
     "iopub.status.idle": "2025-04-12T19:02:08.676860Z",
     "shell.execute_reply": "2025-04-12T19:02:08.676304Z",
     "shell.execute_reply.started": "2025-04-12T18:59:24.638178Z"
    },
    "id": "0iqBaVo0T_dm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_data['cleaned_text'] = training_data['text'].apply(remove_punctuation)\n",
    "training_data['cleaned_title'] = training_data['title'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:02:08.678146Z",
     "iopub.status.busy": "2025-04-12T19:02:08.677907Z",
     "iopub.status.idle": "2025-04-12T19:02:08.691197Z",
     "shell.execute_reply": "2025-04-12T19:02:08.690533Z",
     "shell.execute_reply.started": "2025-04-12T19:02:08.678130Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Port St Lucie Florida'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['cleaned_title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:02:37.996986Z",
     "iopub.status.busy": "2025-04-12T19:02:37.996665Z",
     "iopub.status.idle": "2025-04-12T19:02:44.220440Z",
     "shell.execute_reply": "2025-04-12T19:02:44.219821Z",
     "shell.execute_reply.started": "2025-04-12T19:02:37.996965Z"
    },
    "id": "8Vd0adIJUQJl",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_data['cleaned_text'] = validation_data['text'].apply(remove_punctuation)\n",
    "validation_data['cleaned_title'] = validation_data['title'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:02:44.221682Z",
     "iopub.status.busy": "2025-04-12T19:02:44.221426Z",
     "iopub.status.idle": "2025-04-12T19:02:45.511033Z",
     "shell.execute_reply": "2025-04-12T19:02:45.510212Z",
     "shell.execute_reply.started": "2025-04-12T19:02:44.221655Z"
    },
    "id": "61ur2q9nVfbO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_data['cleaned_text'] = test_data['text'].apply(remove_punctuation)\n",
    "test_data['cleaned_title'] = test_data['title'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:06:49.074478Z",
     "iopub.status.busy": "2025-04-12T19:06:49.074188Z",
     "iopub.status.idle": "2025-04-12T19:06:49.079207Z",
     "shell.execute_reply": "2025-04-12T19:06:49.078519Z",
     "shell.execute_reply.started": "2025-04-12T19:06:49.074459Z"
    },
    "id": "_N0GFhUPVsDW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = str(text)\n",
    "\n",
    "    # Define stopwords set\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize text into words\n",
    "    tokens = re.findall(r\"\\w+\", text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Join the words back into a single string\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:06:50.793653Z",
     "iopub.status.busy": "2025-04-12T19:06:50.793194Z",
     "iopub.status.idle": "2025-04-12T19:06:53.989298Z",
     "shell.execute_reply": "2025-04-12T19:06:53.988656Z",
     "shell.execute_reply.started": "2025-04-12T19:06:50.793628Z"
    },
    "id": "3pjZsdYGV1DN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_data['stopwords_text'] = training_data['cleaned_text'].apply(remove_stopwords)\n",
    "training_data['stopwords_title'] = training_data['cleaned_title'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:06:53.990525Z",
     "iopub.status.busy": "2025-04-12T19:06:53.990302Z",
     "iopub.status.idle": "2025-04-12T19:06:53.995531Z",
     "shell.execute_reply": "2025-04-12T19:06:53.994851Z",
     "shell.execute_reply.started": "2025-04-12T19:06:53.990508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Port St Lucie Florida'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['stopwords_title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:06:58.399058Z",
     "iopub.status.busy": "2025-04-12T19:06:58.398495Z",
     "iopub.status.idle": "2025-04-12T19:06:58.609650Z",
     "shell.execute_reply": "2025-04-12T19:06:58.608906Z",
     "shell.execute_reply.started": "2025-04-12T19:06:58.399034Z"
    },
    "id": "-gNYv0ceV4f2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_data['stopwords_text'] = validation_data['cleaned_text'].apply(remove_punctuation)\n",
    "validation_data['stopwords_title'] = validation_data['cleaned_title'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:06:58.701974Z",
     "iopub.status.busy": "2025-04-12T19:06:58.701262Z",
     "iopub.status.idle": "2025-04-12T19:06:58.752512Z",
     "shell.execute_reply": "2025-04-12T19:06:58.751880Z",
     "shell.execute_reply.started": "2025-04-12T19:06:58.701941Z"
    },
    "id": "lV-xpQajV_Gd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_data['stopwords_text'] = test_data['cleaned_text'].apply(remove_punctuation)\n",
    "test_data['stopwords_title'] = test_data['cleaned_title'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:07:38.898958Z",
     "iopub.status.busy": "2025-04-12T19:07:38.898389Z",
     "iopub.status.idle": "2025-04-12T19:07:38.903142Z",
     "shell.execute_reply": "2025-04-12T19:07:38.902222Z",
     "shell.execute_reply.started": "2025-04-12T19:07:38.898934Z"
    },
    "id": "D47MpX3GWDc-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    \"\"\"\n",
    "    Performs Porter Stemming on the given text.\n",
    "    \"\"\"\n",
    "    pstem = PorterStemmer()\n",
    "    text = str(text)\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    tokens = re.findall(r\"\\w+\", text)\n",
    "\n",
    "    # Perform stemming on each token\n",
    "    stemmed_words = [pstem.stem(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:07:40.313746Z",
     "iopub.status.busy": "2025-04-12T19:07:40.313061Z",
     "iopub.status.idle": "2025-04-12T19:07:57.801946Z",
     "shell.execute_reply": "2025-04-12T19:07:57.801341Z",
     "shell.execute_reply.started": "2025-04-12T19:07:40.313722Z"
    },
    "id": "iKrxqpBaWGa7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_data['stem_text'] = training_data['stopwords_text'].apply(stem_text)\n",
    "training_data['stem_title'] = training_data['stopwords_title'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:07:57.803475Z",
     "iopub.status.busy": "2025-04-12T19:07:57.803184Z",
     "iopub.status.idle": "2025-04-12T19:07:57.808419Z",
     "shell.execute_reply": "2025-04-12T19:07:57.807852Z",
     "shell.execute_reply.started": "2025-04-12T19:07:57.803450Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'port st luci florida'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['stem_title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:08:08.999867Z",
     "iopub.status.busy": "2025-04-12T19:08:08.999583Z",
     "iopub.status.idle": "2025-04-12T19:08:09.743924Z",
     "shell.execute_reply": "2025-04-12T19:08:09.743093Z",
     "shell.execute_reply.started": "2025-04-12T19:08:08.999844Z"
    },
    "id": "FWlYMkiWWJ3s",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_data['stem_text'] = validation_data['stopwords_text'].apply(stem_text)\n",
    "validation_data['stem_title'] = validation_data['stopwords_title'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:08:09.745281Z",
     "iopub.status.busy": "2025-04-12T19:08:09.744941Z",
     "iopub.status.idle": "2025-04-12T19:08:09.899068Z",
     "shell.execute_reply": "2025-04-12T19:08:09.898274Z",
     "shell.execute_reply.started": "2025-04-12T19:08:09.745254Z"
    },
    "id": "z-6cfGvuWNyr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_data['stem_text'] = test_data['stopwords_text'].apply(stem_text)\n",
    "test_data['stem_title'] = test_data['stopwords_title'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:08:33.566168Z",
     "iopub.status.busy": "2025-04-12T19:08:33.565910Z",
     "iopub.status.idle": "2025-04-12T19:08:33.570541Z",
     "shell.execute_reply": "2025-04-12T19:08:33.569850Z",
     "shell.execute_reply.started": "2025-04-12T19:08:33.566149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Performs WordNet Lemmatization on the given text.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = str(text)\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    tokens = re.findall(r\"\\w+\", text)\n",
    "\n",
    "    # Perform lemmatization on each token\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:08:37.699151Z",
     "iopub.status.busy": "2025-04-12T19:08:37.698587Z",
     "iopub.status.idle": "2025-04-12T19:08:44.717785Z",
     "shell.execute_reply": "2025-04-12T19:08:44.717174Z",
     "shell.execute_reply.started": "2025-04-12T19:08:37.699128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_data['lem_text'] = training_data['stopwords_text'].apply(lemmatize_text)\n",
    "training_data['lem_title'] = training_data['stopwords_title'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:08:50.105611Z",
     "iopub.status.busy": "2025-04-12T19:08:50.105055Z",
     "iopub.status.idle": "2025-04-12T19:08:50.110460Z",
     "shell.execute_reply": "2025-04-12T19:08:50.109858Z",
     "shell.execute_reply.started": "2025-04-12T19:08:50.105588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Port St Lucie Florida'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['lem_title'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:08:53.521068Z",
     "iopub.status.busy": "2025-04-12T19:08:53.520817Z",
     "iopub.status.idle": "2025-04-12T19:08:53.567068Z",
     "shell.execute_reply": "2025-04-12T19:08:53.566339Z",
     "shell.execute_reply.started": "2025-04-12T19:08:53.521052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_data['lem_text'] = test_data['stopwords_text'].apply(lemmatize_text)\n",
    "test_data['lem_title'] = test_data['stopwords_title'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:08:53.815360Z",
     "iopub.status.busy": "2025-04-12T19:08:53.814690Z",
     "iopub.status.idle": "2025-04-12T19:08:54.008969Z",
     "shell.execute_reply": "2025-04-12T19:08:54.008177Z",
     "shell.execute_reply.started": "2025-04-12T19:08:53.815331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_data['lem_text'] = validation_data['stopwords_text'].apply(lemmatize_text)\n",
    "validation_data['lem_title'] = validation_data['stopwords_title'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:08:57.506140Z",
     "iopub.status.busy": "2025-04-12T19:08:57.505746Z",
     "iopub.status.idle": "2025-04-12T19:09:04.886659Z",
     "shell.execute_reply": "2025-04-12T19:09:04.885970Z",
     "shell.execute_reply.started": "2025-04-12T19:08:57.506116Z"
    },
    "id": "ZwproHhpVW45",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save as csv file\n",
    "training_data.to_csv('train_preprocessed.csv', index=False)\n",
    "validation_data.to_csv('val_preprocessed.csv', index=False)\n",
    "test_data.to_csv('test_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:09:04.888383Z",
     "iopub.status.busy": "2025-04-12T19:09:04.888052Z",
     "iopub.status.idle": "2025-04-12T19:09:07.895922Z",
     "shell.execute_reply": "2025-04-12T19:09:07.895142Z",
     "shell.execute_reply.started": "2025-04-12T19:09:04.888356Z"
    },
    "id": "9IFU7jR2Wj_k",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest length in 'title': 63\n",
      "Smallest length in 'title': 1\n",
      "Largest length in 'text': 296253\n",
      "Smallest length in 'text': 320\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('train_preprocessed.csv')\n",
    "\n",
    "# Find the largest and smallest lengths in 'stem_title'\n",
    "max_title_length = df['title'].str.len().max()\n",
    "min_title_length = df['title'].str.len().min()\n",
    "\n",
    "# Find the largest and smallest lengths in 'stem_text'\n",
    "max_text_length = df['text'].str.len().max()\n",
    "min_text_length = df['text'].str.len().min()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Largest length in 'title': {max_title_length}\")\n",
    "print(f\"Smallest length in 'title': {min_title_length}\")\n",
    "print(f\"Largest length in 'text': {max_text_length}\")\n",
    "print(f\"Smallest length in 'text': {min_text_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:09:07.896855Z",
     "iopub.status.busy": "2025-04-12T19:09:07.896591Z",
     "iopub.status.idle": "2025-04-12T19:09:11.004504Z",
     "shell.execute_reply": "2025-04-12T19:09:11.003912Z",
     "shell.execute_reply.started": "2025-04-12T19:09:07.896828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest length in 'lem_title': 58.0\n",
      "Smallest length in 'lem_title': 1.0\n",
      "Largest length in 'lem_text': 65429\n",
      "Smallest length in 'lem_text': 5\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('train_preprocessed.csv')\n",
    "\n",
    "# Find the largest and smallest lengths in 'lem_title'\n",
    "max_title_length = df['lem_title'].str.len().max()\n",
    "min_title_length = df['lem_title'].str.len().min()\n",
    "\n",
    "# Find the largest and smallest lengths in 'lem_text'\n",
    "max_text_length = df['lem_text'].str.len().max()\n",
    "min_text_length = df['lem_text'].str.len().min()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Largest length in 'lem_title': {max_title_length}\")\n",
    "print(f\"Smallest length in 'lem_title': {min_title_length}\")\n",
    "print(f\"Largest length in 'lem_text': {max_text_length}\")\n",
    "print(f\"Smallest length in 'lem_text': {min_text_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:09:11.005846Z",
     "iopub.status.busy": "2025-04-12T19:09:11.005648Z",
     "iopub.status.idle": "2025-04-12T19:09:14.011395Z",
     "shell.execute_reply": "2025-04-12T19:09:14.010668Z",
     "shell.execute_reply.started": "2025-04-12T19:09:11.005831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest length in 'stem_title': 55.0\n",
      "Smallest length in 'stem_title': 1.0\n",
      "Largest length in 'stem_text': 63165\n",
      "Smallest length in 'stem_text': 4\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('train_preprocessed.csv')\n",
    "\n",
    "# Find the largest and smallest lengths in 'stem_title'\n",
    "max_title_length = df['stem_title'].str.len().max()\n",
    "min_title_length = df['stem_title'].str.len().min()\n",
    "\n",
    "# Find the largest and smallest lengths in 'stem_text'\n",
    "max_text_length = df['stem_text'].str.len().max()\n",
    "min_text_length = df['stem_text'].str.len().min()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Largest length in 'stem_title': {max_title_length}\")\n",
    "print(f\"Smallest length in 'stem_title': {min_title_length}\")\n",
    "print(f\"Largest length in 'stem_text': {max_text_length}\")\n",
    "print(f\"Smallest length in 'stem_text': {min_text_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7118719,
     "sourceId": 11371385,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7124390,
     "sourceId": 11378884,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
